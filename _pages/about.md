---
layout: about
title: about
permalink: /
description: 

profile:
  align: right
  image: picture3.jpeg
  
scholar:
  sort_by: year
  order: descending  # can be either "ascending" or "descending"

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---
I am a fourth-year PhD student at the [Computational Linguistics and Text Mining Lab (CLTL)](https://home.cltl.labs.vu.nl/) 
at the [Vrije Universiteit Amsterdam](https://vu.nl/nl). 
I am advised by [Antske Fokkens](http://wordpress.let.vupr.nl/antske/) (Vrije Universiteit Amsterdam) 
and [Eric Nalisnick](https://enalisnick.github.io/) (Johns Hopkins University). 

I am passionate about understanding _what_ knowledge a language model has captured and whether it 
can **reliably** apply this knowledge across diverse (unseen) contexts; what will its **impact** 
be in the real world? I am particularly interested in analyzing and developing tools to ensure 
**responsible deployment**, with a big focus on **robustness** for _safety-critical applications_, e.g. hate speech detection. 

My work includes evaluating the generalization of model capabilities to unseen data, for 
instance [through the lens of model averaging and consistency](https://aclanthology.org/2021.eval4nlp-1.3). 
I have also proposed a method to [calibrate language models according to human subjectivity](https://openreview.net/forum?id=VWWzO3ewMS). 
Collaborating in an interdisciplinary environment with a social scientist and law expert, I 
characterized the [subjective aspects of hate speech and its impact on real-world deployment](https://aclanthology.org/2022.woah-1.17). 
Building on these insights, I developed a [framework to evaluate if a hate speech detection modelâ€™s 
behavior aligns with the type of hate speech it is intended to address](https://arxiv.org/abs/2410.15911). 

I earned my BSc and MSc degrees in Artificial Intelligence from the University of Amsterdam.
#### research interests.
Making a _positive_ impact is what drives me. Hence, the following research topics and questions 
are (amongst others) what my current interests are and what I want to work on in the future: 

**Understanding generalization capabilities.** This includes rigorous analyses of model capabilities 
and extensive **model evaluation**;
designing tools and metrics that go beyond aggregate metrics to give us more insight into model 
strengths and weaknesses. _What is in the data? What did the model learn from it? What does this 
mean for real-world data?_
  
**AI for social good.** Language models are increasingly affecting our daily lives and especially 
certain applications require us to develop models with a lot of care. This goes beyond the 
conventional performance-driven model development. _How can we address such safety-critical applications?_ 

**Multicultural Human-Centred systems design.** As end-users of most language models, it is of 
utmost importance that the systems are designed with keeping humans in mind. Every user comes 
with their own experience, values, and beliefs. _How can we design adaptive systems that accommodate 
this diversity and subjectivity? How can we ensure that our systems are useful for a wide set of users?_ 
